{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from scipy.misc import imresize\n",
    "from scipy.misc import imsave\n",
    "import multiprocessing\n",
    "\n",
    "train_val_root = '/usr/stud/wangyu/DAVIS17_train_val'\n",
    "test_dev_root = '/usr/stud/wangyu/DAVIS17_test_dev'\n",
    "test_challenge_root = '/usr/stud/wangyu/DAVIS17_test_challenge'\n",
    "train_list_txt = '/usr/stud/wangyu/DAVIS17_train_val/ImageSets/2017/train.txt'\n",
    "val_list_txt = '/usr/stud/wangyu/DAVIS17_train_val/ImageSets/2017/val.txt'\n",
    "NUM_PROCESSES = 3\n",
    "\n",
    "def get_file_list(train_val_root, train_list_txt, val_list_txt, test_dev_root, test_challenge_root):\n",
    "    'Get all RGB images and corresponding labels'\n",
    "    # create train, val, test_dev, test_challenge list files\n",
    "    train_list = open('train_list.txt','w')\n",
    "    train_gt_list = open('train_gt_list.txt', 'w')\n",
    "    val_list = open('val_list.txt', 'w')\n",
    "    val_gt_list = open('val_gt_list.txt', 'w')\n",
    "    \n",
    "    # train, val, test_dev, test_challenge file lists\n",
    "    files_train_img = []\n",
    "    files_train_gts = []\n",
    "    files_val_img = []\n",
    "    files_val_gts = []\n",
    "    files_dev_img = []\n",
    "    files_challenge_img = []\n",
    "    \n",
    "    # train list\n",
    "    with open(train_list_txt) as t:\n",
    "        train_seqs = t.read().splitlines()\n",
    "    for i in range(len(train_seqs)):\n",
    "        seq = train_seqs[i]\n",
    "        search_seq_imgs = os.path.join( train_val_root , \"JPEGImages\" , \"480p\" , seq , \"*.jpg\" )\n",
    "        search_seq_gts = os.path.join( train_val_root , \"Annotations\" , \"480p\" , seq , \"*.png\" )\n",
    "        files_seq_imgs = glob.glob(search_seq_imgs)\n",
    "        files_seq_gts = glob.glob(search_seq_gts)\n",
    "        files_seq_imgs.sort()\n",
    "        files_seq_gts.sort()\n",
    "        if len(files_seq_imgs) != len(files_seq_gts):\n",
    "            sys.exit('Sequence {} train/gt lenght do not match.'.format(seq))\n",
    "        files_train_img += files_seq_imgs\n",
    "        files_train_gts += files_seq_gts\n",
    "        for j in range(len(files_seq_imgs)):\n",
    "            train_list.write(\"%s\\n\" % files_seq_imgs[j])\n",
    "            train_gt_list.write(\"%s\\n\" % files_seq_gts[j])\n",
    "    train_list.close()\n",
    "    train_gt_list.close()\n",
    "    # grouping train/gt pairs\n",
    "    train_pair_list = []\n",
    "    for i in range(len(files_train_img)):\n",
    "        train_pair_list.append([files_train_img[i], files_train_gts[i]])\n",
    "    \n",
    "    # val list\n",
    "    with open(val_list_txt) as t:\n",
    "        val_seqs = t.read().splitlines()\n",
    "    for i in range(len(val_seqs)):\n",
    "        seq = val_seqs[i]\n",
    "        search_seq_imgs = os.path.join( train_val_root , \"JPEGImages\" , \"480p\" , seq , \"*.jpg\" )\n",
    "        search_seq_gts = os.path.join( train_val_root , \"Annotations\" , \"480p\" , seq , \"*.png\" )\n",
    "        files_seq_imgs = glob.glob(search_seq_imgs)\n",
    "        files_seq_gts = glob.glob(search_seq_gts)\n",
    "        files_seq_imgs.sort()\n",
    "        files_seq_gts.sort()\n",
    "        if len(files_seq_imgs) != len(files_seq_gts):\n",
    "            sys.exit('Sequence {} train/gt lenght do not match.'.format(seq))\n",
    "        files_val_img += files_seq_imgs\n",
    "        files_val_gts += files_seq_gts\n",
    "        for j in range(len(files_seq_imgs)):\n",
    "            val_list.write(\"%s\\n\" % files_seq_imgs[j])\n",
    "            val_gt_list.write(\"%s\\n\" % files_seq_gts[j])\n",
    "    val_list.close()\n",
    "    val_gt_list.close()\n",
    "    # grouping val/gt pairs\n",
    "    val_pair_list = []\n",
    "    for i in range(len(files_val_img)):\n",
    "        val_pair_list.append([files_val_img[i], files_val_gts[i]])\n",
    "    print('Got {0} train/gt files. {1} val files.'.format(len(train_pair_list), len(val_pair_list)))\n",
    "    \n",
    "    # test-dev and test-challenge lists\n",
    "    search_dev_imgs = os.path.join( test_dev_root , \"JPEGImages\" , \"480p\" , \"*\" , \"*.jpg\" )\n",
    "    search_challenge_imgs = os.path.join( test_challenge_root , \"JPEGImages\" , \"480p\" , \"*\" , \"*.jpg\" )\n",
    "    files_dev_img = glob.glob(search_dev_imgs)\n",
    "    files_challenge_img = glob.glob(search_challenge_imgs)\n",
    "    files_dev_img.sort()\n",
    "    files_challenge_img.sort()\n",
    "    print('Got {0} test_dev files. {1} test_challenge files.'.format(len(files_dev_img),len(files_challenge_img)))\n",
    "    \n",
    "    return train_pair_list, val_pair_list, files_dev_img, files_challenge_img\n",
    "\n",
    "def load_img(file_pair, mode):\n",
    "    ''' Input:  a list of length 2: [img_name, gt_name]\n",
    "        Return: two arrays: [img_arr, gt_arr]\n",
    "            img_arr: [480,910,3] or [480,854,3] or [480,911,3]\n",
    "            gt_arr: [480,910] or [480,854,3] or [480,911,3]\n",
    "    '''\n",
    "    if mode == 'train' or mode == 'val':\n",
    "        img = Image.open(file_pair[0])\n",
    "        image = np.array(img, dtype=np.uint8)\n",
    "    \n",
    "        gt = Image.open(file_pair[1])\n",
    "        gt_label = np.array(gt, dtype=np.uint8)\n",
    "        gt_label_bool = np.greater(gt_label,0)\n",
    "        gt_label_bin = gt_label_bool.astype(np.uint8)\n",
    "        if mode == 'train':\n",
    "            img_sc = imresize(img, (854,480))\n",
    "            image = np.array(img_sc, dtype=np.uint8)\n",
    "            # nearest interp for labels since they are discrete values\n",
    "            gt_label_bin_sc = imresize(gt_label_bin, (854,480), interp='nearest')\n",
    "            gt_label_bin = np.array(gt_label_bin_sc, dtype=np.uint8)\n",
    "    elif mode == 'test':                                                   \n",
    "        img = Image.open(file_pair)\n",
    "        image = np.array(img, dtype=np.uint8)\n",
    "        gt_label_bin = None\n",
    "    else:\n",
    "        image = None\n",
    "        gt_label_bin = None\n",
    "    \n",
    "    return image, gt_label_bin\n",
    "\n",
    "def resize_pair(img, gt, scale):\n",
    "    ''' Input: img/gt in full size [480,910] or [480,854] or [480,911]\n",
    "        Return: resize img/gt [H*scale, W*scale]\n",
    "            scale: 0.5, 0.8, 1.0\n",
    "    '''\n",
    "    img_sc = imresize(img, scale)\n",
    "    gt_sc = imresize(gt,scale)\n",
    "    new_img = np.array(img_sc, dtype=np.uint8)\n",
    "    new_gt = np.array(gt_sc, dtype=np.uint8)\n",
    "    \n",
    "    return new_img, new_gt\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def wrap_a_data_dict(file_pair):\n",
    "    ''' Input: [img_name, gt_name]\n",
    "        Return: Dict\n",
    "    '''\n",
    "    data_dict = {}\n",
    "    data_dict['img'], data_dict['gt'] = load_img(file_pair, 'train')\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "def write_single_record(record_writer, data_dict):\n",
    "    ''' Input: record_writer, single data_dict\n",
    "        Return: No return.\n",
    "    '''\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                                'img': _int64_feature(data_dict['img'].flatten()),\n",
    "                                'gt': _int64_feature(data_dict['gt'].flatten()),}))\n",
    "    record_writer.write(example.SerializeToString())\n",
    "    \n",
    "def generate_tfrecords(files_list, record_writer):\n",
    "    \n",
    "    for example_file_list in files_list:\n",
    "        # Get all necessary data\n",
    "        data_dict = wrap_a_data_dict(example_file_list)\n",
    "        # Write a single record/exampel to .tfrecord\n",
    "        write_single_record(record_writer, data_dict)\n",
    "        example_name = example_file_list[0].replace('.jpg', '')\n",
    "        print('Write example: {}'.format(example_name))\n",
    "    record_writer.flush()\n",
    "    record_writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 4209 train/gt files. 1999 val files.\n",
      "Got 2086 test_dev files. 2180 test_challenge files.\n",
      "Computing train_list ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/stud/wangyu/.local/lib/python2.7/site-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/usr/stud/wangyu/.local/lib/python2.7/site-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing val list ...\n",
      "Computing test_dev list ...\n",
      "Computing test_challenge list ...\n",
      "Num pixels per channel: 4331701920\n",
      "Sum in R: 498993995102\n",
      "Sum in G: 497831571421\n",
      "Sum in B: 466635839444\n",
      "R:115.195829334, G:114.927476686, B:107.725750308\n"
     ]
    }
   ],
   "source": [
    "## Compute RGB mean and variance of dataset(DAVIS17_train_val, DAVIS17_test_dev, DAVIS17_test_challenge)\n",
    "train_pair_list, val_pair_list, test_dev_list, test_challenge_list = get_file_list(train_val_root, \n",
    "                                                                                   train_list_txt, \n",
    "                                                                                   val_list_txt,\n",
    "                                                                                   test_dev_root,\n",
    "                                                                                   test_challenge_root)\n",
    "\n",
    "len_train = len(train_pair_list)\n",
    "len_val = len(val_pair_list)\n",
    "len_test_dev = len(test_dev_list)\n",
    "len_test_challenge = len(test_challenge_list)\n",
    "\n",
    "mean_r = 0.0\n",
    "mean_g = 0.0\n",
    "mean_b = 0.0\n",
    "std = 1.0\n",
    "\n",
    "sum_r_all = []\n",
    "sum_g_all = []\n",
    "sum_b_all = []\n",
    "                                                                             \n",
    "num_pixels_all_single_chanel = 0\n",
    "\n",
    "# Only for train set, to verify images have the same size.\n",
    "image, gt = load_img(train_pair_list[0], 'train')\n",
    "last_img_name = train_pair_list[0][0]\n",
    "last_h = image.shape[0]\n",
    "last_w = image.shape[1]\n",
    "print(\"Computing train_list ...\")\n",
    "for i in range(len_train):\n",
    "    image, gt = load_img(train_pair_list[i], 'train')\n",
    "    if image.shape[0] != last_h or image.shape[1] != last_w:\n",
    "        sys.exit(\"train images have different sizes: {0}, {1}\".format(last_img_name, train_pair_list[i][0]))\n",
    "    else:\n",
    "        last_h = image.shape[0]\n",
    "        last_w = image.shape[1]\n",
    "        last_img_name = train_pair_list[i][0]\n",
    "    sum_r_all.append( np.sum(image[:,:,0]) )\n",
    "    sum_g_all.append( np.sum(image[:,:,1]) )\n",
    "    sum_b_all.append( np.sum(image[:,:,2]) )\n",
    "    num_pixels_all_single_chanel += image.shape[0] * image.shape[1]\n",
    "\n",
    "print(\"Computing val list ...\")\n",
    "for l in range(len_val):\n",
    "    image, gt = load_img(val_pair_list[l], 'val')\n",
    "    sum_r_all.append( np.sum(image[:,:,0]) )\n",
    "    sum_g_all.append( np.sum(image[:,:,1]) )\n",
    "    sum_b_all.append( np.sum(image[:,:,2]) )\n",
    "    num_pixels_all_single_chanel += image.shape[0] * image.shape[1]\n",
    "\n",
    "print(\"Computing test_dev list ...\")\n",
    "for j in range(len_test_dev):\n",
    "    image, gt = load_img(test_dev_list[j], 'test')\n",
    "    sum_r_all.append( np.sum(image[:,:,0]) )\n",
    "    sum_g_all.append( np.sum(image[:,:,1]) )\n",
    "    sum_b_all.append( np.sum(image[:,:,2]) )\n",
    "    num_pixels_all_single_chanel += image.shape[0] * image.shape[1]\n",
    "\n",
    "print(\"Computing test_challenge list ...\")\n",
    "for k in range(len_test_challenge):\n",
    "    image, gt = load_img(test_challenge_list[k], 'test')\n",
    "    sum_r_all.append( np.sum(image[:,:,0]) )\n",
    "    sum_g_all.append( np.sum(image[:,:,1]) )\n",
    "    sum_b_all.append( np.sum(image[:,:,2]) )\n",
    "    num_pixels_all_single_chanel += image.shape[0] * image.shape[1]\n",
    "\n",
    "mean_r = np.sum(sum_r_all) / num_pixels_all_single_chanel\n",
    "mean_g = np.sum(sum_g_all) / num_pixels_all_single_chanel\n",
    "mean_b = np.sum(sum_b_all) / num_pixels_all_single_chanel\n",
    "\n",
    "print('Num pixels per channel: {0}'.format(num_pixels_all_single_chanel))\n",
    "print('Sum in R: {0}'.format(np.sum(sum_r_all)))\n",
    "print('Sum in G: {0}'.format(np.sum(sum_g_all)))\n",
    "print('Sum in B: {0}'.format(np.sum(sum_b_all)))\n",
    "print('R:{0}, G:{1}, B:{2}'.format(mean_r, mean_g, mean_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing train list ...\n",
      "Computing val list ...\n",
      "Computing test_dev list ...\n",
      "Computing test_challenge list ...\n",
      "R:64.5572961827, G:63.0172054007, B:67.0494050908\n"
     ]
    }
   ],
   "source": [
    "## Compute RGB variance of dataset(DAVIS17_train_val, DAVIS17_test_dev, DAVIS17_test_challenge)\n",
    "num_pixels_all_single_chanel = 4331701920\n",
    "\n",
    "std_r = 0.0\n",
    "std_g = 0.0\n",
    "std_b = 0.0\n",
    "\n",
    "std_r_all = []\n",
    "std_g_all = []\n",
    "std_b_all = []\n",
    "\n",
    "print('Computing train list ...')\n",
    "for i in range(len_train):\n",
    "    image, gt = load_img(train_pair_list[i], 'train')\n",
    "    std_r_all.append(np.sum(np.square(image[:,:,0] - 115.195829334)))\n",
    "    std_g_all.append(np.sum(np.square(image[:,:,1] - 114.927476686)))\n",
    "    std_b_all.append(np.sum(np.square(image[:,:,2] - 107.725750308)))\n",
    "    \n",
    "print(\"Computing val list ...\")\n",
    "for l in range(len_val):\n",
    "    image, gt = load_img(val_pair_list[l], 'val')\n",
    "    std_r_all.append(np.sum(np.square(image[:,:,0] - 115.195829334)))\n",
    "    std_g_all.append(np.sum(np.square(image[:,:,1] - 114.927476686)))\n",
    "    std_b_all.append(np.sum(np.square(image[:,:,2] - 107.725750308)))\n",
    "    \n",
    "    \n",
    "print('Computing test_dev list ...')\n",
    "for j in range(len_test_dev):\n",
    "    image, gt = load_img(test_dev_list[j], 'test')\n",
    "    std_r_all.append(np.sum(np.square(image[:,:,0] - 115.195829334)))\n",
    "    std_g_all.append(np.sum(np.square(image[:,:,1] - 114.927476686)))\n",
    "    std_b_all.append(np.sum(np.square(image[:,:,2] - 107.725750308)))\n",
    "\n",
    "print(\"Computing test_challenge list ...\")\n",
    "for k in range(len_test_challenge):\n",
    "    image, gt = load_img(test_challenge_list[k], 'test')\n",
    "    std_r_all.append(np.sum(np.square(image[:,:,0] - 115.195829334)))\n",
    "    std_g_all.append(np.sum(np.square(image[:,:,1] - 114.927476686)))\n",
    "    std_b_all.append(np.sum(np.square(image[:,:,2] - 107.725750308)))\n",
    "    \n",
    "std_r = np.sqrt(np.sum(std_r_all) / num_pixels_all_single_chanel)\n",
    "std_g = np.sqrt(np.sum(std_g_all) / num_pixels_all_single_chanel)\n",
    "std_b = np.sqrt(np.sum(std_b_all) / num_pixels_all_single_chanel)\n",
    "\n",
    "print('R:{0}, G:{1}, B:{2}'.format(std_r, std_g, std_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_txt = '/usr/stud/wangyu/DAVIS17_train_val/ImageSets/2017/train.txt'\n",
    "with open(train_list_txt) as t:\n",
    "    train_paths = t.read().splitlines()\n",
    "print(len(train_paths))\n",
    "print(train_paths[0])\n",
    "\n",
    "train_list = open('train_list.txt','a')\n",
    "\n",
    "for i in range(len(train_paths)):\n",
    "    seq = train_paths[i]\n",
    "    search_seq_imgs = os.path.join( \"/usr/stud/wangyu/DAVIS17_train_val\" , \"JPEGImages\" , \"480p\" , seq , \"*.jpg\" )\n",
    "    files_seq_imgs = glob.glob(search_seq_imgs)\n",
    "    files_seq_imgs.sort()\n",
    "    for img_file in files_seq_imgs:\n",
    "        train_list.write(\"%s\\n\" % img_file)\n",
    "    \n",
    "    print(len(files_seq_imgs))\n",
    "    print(files_seq_imgs[81])\n",
    "    \n",
    "    train_list.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "from scipy.misc import toimage\n",
    "from skimage.transform import resize\n",
    "from scipy.misc import imresize\n",
    "img_name = '/usr/stud/wangyu/DAVIS17_train_val/Annotations/480p/cat-girl/00000.png'\n",
    "img = Image.open(img_name)\n",
    "image = np.array(img, dtype=np.uint8)\n",
    "img_sc = imresize(image, (480,854), interp='nearest')\n",
    "\n",
    "imsave('re_cat_girl.png', img_sc)\n",
    "\n",
    "# f = Image.fromarray(image, mode='P')\n",
    "# f.save('re_cat_girl.png')\n",
    "\n",
    "# toimage(image, cmin=0, cmax=255).save('re_cat_girl.png')\n",
    "\n",
    "# img2 = np.array(Image.open('re_cat_girl.png'),dtype=np.uint8)\n",
    "# if img2.all() == image.all():\n",
    "#     print('Yes')\n",
    "# print(img_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
